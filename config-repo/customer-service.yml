server:
  port: ${PORT:0}

customer-service:
  customer-topic-name: customer

spring:
  application:
    name: customer-service
  jpa:
    open-in-view: false
    show-sql: true
    hibernate:
      ddl-auto: update

  datasource:
    url: jdbc:postgresql://192.168.50.141:5433/hshop?currentSchema=customer&binaryTransfer=true&reWriteBatchedInserts=true&stringtype=unspecified
    username: postgres
    password: qwe123
    driver-class-name: org.postgresql.Driver
    platform: postgres

#  sql:
#    init:
#      mode: ALWAYS
#      schema-locations: classpath:init-schema.sql,classpath:init-data.sql

eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:8010/eureka
  instance:
    instance-id: ${spring.application.name}:${spring.application.instance_id:${random.value}}


kafka-config:
  bootstrap-servers: 192.168.50.141:19092, 192.168.50.141:29092, 192.168.50.141:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://192.168.50.141:8081
  num-of-partitions: 3
  replication-factor: 3

kafka-producer-config:
  key-serializer-class: org.apache.kafka.common.serialization.StringSerializer
  value-serializer-class: io.confluent.kafka.serializers.KafkaAvroSerializer
  compression-type: snappy
  acks: all
  batch-size: 16384
  batch-size-boost-factor: 100
  linger-ms: 5
  request-timeout-ms: 60000
  retry-count: 5

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  auto-offset-reset: earliest
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true
  auto-startup: true
  concurrency-level: 3
  session-timeout-ms: 10000
  heartbeat-interval-ms: 3000
  max-poll-interval-ms: 300000
  max-poll-records: 500
  max-partition-fetch-bytes-default: 1048576
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150

login:
  url:
    path: '/login'